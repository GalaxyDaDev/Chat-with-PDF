{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ffa5780d-c029-4a48-8d33-a3a800fb5af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyPDF2 import PdfReader\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "import faiss\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ed8fe346-40f7-49bc-8ea3-905e82bc624c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(pdf_file):\n",
    "    raw_text = ''\n",
    "    pdf_reader = PdfReader(pdf_file)\n",
    "    for i, page in enumerate(pdf_reader.pages):\n",
    "        content = page.extract_text()\n",
    "        if content:\n",
    "            raw_text += content\n",
    "        else:\n",
    "            print(f\"Warning: No content extracted from page {i} of {pdf_file}\")\n",
    "\n",
    "    if not raw_text:\n",
    "        print(f\"Warning: No text extracted from {pdf_file}. Skipping this file.\")\n",
    "    return raw_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8c68b502-8325-4582-b137-0de84788518a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embeddings(text, model):\n",
    "    sentences = text.split('\\n')\n",
    "    embeddings = model.encode(sentences, convert_to_tensor=True)\n",
    "    return sentences, embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d86c9172-faa6-433a-8c72-ed03ef9ebd2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "46256e89-ab06-4e12-a316-a416ed2aa6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the DB and extracted content\n",
    "output_directory = r\"C:\\Users\\harsh\\Desktop\\Gen AI Projects\\ChatPDF\\Performance Measure\\Sample DB\"\n",
    "os.makedirs(output_directory, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c97b6f1a-822f-460f-8009-348afdf339ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_file = r\"C:\\Users\\harsh\\Downloads\\Sample PDF.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "32b6af51-4af9-4825-9cb3-cb81474cfd57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting and Embedding contents from PDF\n",
    "all_sentences=[]\n",
    "all_embeddings=[]\n",
    "\n",
    "text = extract_text_from_pdf(pdf_path)\n",
    "sentences, embeddings = create_embeddings(text, model)\n",
    "all_sentences.extend(sentences)\n",
    "all_embeddings.append(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "45be1220-4288-4abd-9c17-064fbb8f180f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(all_sentences[10:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "22b79e34-074a-4bc0-ac88-8334797f6282",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_embeddings = np.vstack(all_embeddings)\n",
    "\n",
    "# Creating FAISS index\n",
    "embedding_dim = all_embeddings.shape[1]\n",
    "index = faiss.IndexFlatL2(embedding_dim)\n",
    "index.add(all_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4e45054a-bf97-4aba-9074-e7d138e70c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "faiss.write_index(index, os.path.join(output_directory, 'vector_store.index'))\n",
    "with open(os.path.join(output_directory, 'sentences.txt'), 'w') as f:\n",
    "    for sentence in all_sentences:\n",
    "        f.write(f\"{sentence}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f07aae00-103d-4d48-9f42-74bed33409b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the saved DB and Content\n",
    "\n",
    "import faiss\n",
    "import os\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import re\n",
    "\n",
    "output_directory = r\"C:\\Users\\harsh\\Desktop\\Gen AI Projects\\ChatPDF\\Performance Measure\\Sample DB\"\n",
    "\n",
    "index = faiss.read_index(os.path.join(output_directory, 'vector_store.index'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2a91233-0101-446c-8053-d1d2cb9d62c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a00d006-5bb8-4a0b-8db9-7523138c36fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(output_directory, 'sentences.txt'), 'r', encoding='utf-8') as f:\n",
    "    sentences = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a259eb6-c151-45af-b76d-7833dac10498",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_similar_sentences(query, model, index, sentences, top_k=5):\n",
    "    query_embedding = model.encode([query], convert_to_tensor=True)\n",
    "    query_embedding_np = query_embedding.cpu().detach().numpy()\n",
    "\n",
    "    # Searching in Faiss index\n",
    "    D, I = index.search(query_embedding_np, top_k)\n",
    "\n",
    "    # Retrieving similar sentences\n",
    "    results = []\n",
    "    for i in range(top_k):\n",
    "        similar_sentence = sentences[I[0][i]].strip()  # Get the sentence\n",
    "        similarity_score = 1 - D[0][i]  # Calculate similarity score (cosine similarity)\n",
    "        results.append((similar_sentence, similarity_score))\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24505a70-11c5-463d-ad7a-13f531cc15cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to ask questions and see similarity search result\n",
    "def ask_multiple_questions(model, index, sentences, top_k=5):\n",
    "    while True:\n",
    "        query = input(\"Enter your question (type 'exit' to quit): \").strip()\n",
    "        if query.lower() == 'exit':\n",
    "            break\n",
    "        \n",
    "        similar_results = search_similar_sentences(query, model, index, sentences, top_k=top_k)\n",
    "        print(f\"Query: {query}\")\n",
    "        for i, (sentence, score) in enumerate(similar_results, start=1):\n",
    "            print(f\"Similar Sentence {i}: {sentence} (Similarity Score: {score:.4f})\")\n",
    "        print()  # Print a blank line for separation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3486e162-7de1-40ff-b8c5-b5f6b458f42f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your question (type 'exit' to quit):  Who was Tom's Friend?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Who was Tom's Friend?\n",
      "Similar Sentence 1: “No,” Tom said, “I can’t be your friend, because the (Similarity Score: 0.4959)\n",
      "Similar Sentence 2: Tom walked to his friend Joe Harper’s house and played (Similarity Score: 0.3403)\n",
      "Similar Sentence 3: Tom Sawyer (Similarity Score: 0.3296)\n",
      "Similar Sentence 4: Then Tom went to school, but he was late. The teacher (Similarity Score: 0.3024)\n",
      "Similar Sentence 5: Tom Sawyer lived with his aunt because his mother and (Similarity Score: 0.2923)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your question (type 'exit' to quit):  At twelve o clock where was Tom?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: At twelve o clock where was Tom?\n",
      "Similar Sentence 1: That night Tom went to bed at nine o’clock, but he (Similarity Score: 0.4182)\n",
      "Similar Sentence 2: One Saturday afternoon Tom wanted to have an adventure (Similarity Score: 0.3186)\n",
      "Similar Sentence 3: Then Tom went to school, but he was late. The teacher (Similarity Score: 0.2898)\n",
      "Similar Sentence 4: Monday morning, Tom went to school. The children wanted to hear about his adventure, and Tom liked (Similarity Score: 0.2793)\n",
      "Similar Sentence 5: Tom went out of the cave. Chapter 11    In the Cave Again (Similarity Score: 0.2598)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your question (type 'exit' to quit):  Who was angry with Tom?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Who was angry with Tom?\n",
      "Similar Sentence 1: Saturday morning, Tom was not happy, but he started to (Similarity Score: 0.3717)\n",
      "Similar Sentence 2: a    is Aunt Polly angry with Tom? (Similarity Score: 0.3690)\n",
      "Similar Sentence 3: The teacher was angry again. “Tom Sawyer, stop (Similarity Score: 0.3632)\n",
      "Similar Sentence 4: But Becky was angry with Tom. She walked away and (Similarity Score: 0.3224)\n",
      "Similar Sentence 5: didn’t answer. Tom was unhappy. He didn’t go to school in the afternoon. (Similarity Score: 0.3120)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Question = ask_multiple_questions(model, index, sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6474b2-6de0-42ce-a252-058502ef702f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-py9",
   "language": "python",
   "name": "test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
